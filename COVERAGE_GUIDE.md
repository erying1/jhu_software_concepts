# Module 4: Reaching 100% Test Coverage

## ğŸ“Š Current Status
- **9 tests passing** (from initial setup)
- **27% coverage**
- **Target: 100% coverage**

## ğŸ¯ New Test Files Created

I've created **5 additional test files** with comprehensive tests:

1. **test_load_data.py** (13 tests)
   - Tests database loading, connection, table creation
   - Tests record normalization and insertion
   - Mocks PostgreSQL interactions

2. **test_query_data.py** (8 tests)
   - Tests all query functions (Q1, Q2, Q3, etc.)
   - Tests formatting helpers
   - Mocks database cursor operations

3. **test_clean.py** (16 tests)
   - Tests data cleaning functions
   - Tests status/citizenship normalization
   - Tests LLM batch processing
   - Handles file I/O

4. **test_scrape.py** (17 tests)
   - Tests web scraping functions
   - Tests HTML parsing
   - Tests parallel fetching
   - Mocks network requests

5. **test_run.py** (2 tests)
   - Tests application entry point
   - Simple but covers the run.py file

**Total: 56 new tests added!**

## âš¡ Quick Installation

```powershell
# Copy all test files to module_4/tests/
Copy-Item test_load_data.py module_4\tests\
Copy-Item test_query_data.py module_4\tests\
Copy-Item test_clean.py module_4\tests\
Copy-Item test_scrape.py module_4\tests\
Copy-Item test_run.py module_4\tests\

# Navigate to module_4
cd module_4

# Run all tests
pytest -v
```

## ğŸ”§ Fixing Import Issues

The new tests use mocking to avoid actual database/network calls. You may need to adjust imports based on your exact file structure.

### Common Fix #1: Import Paths
If you get `ModuleNotFoundError`, update the sys.path lines in each test:

```python
# Change this:
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# To match your structure if needed
```

### Common Fix #2: Module Names
If your modules are named differently, update imports:

```python
# In test_clean.py, change:
from src.module_2.1 import clean

# To match your actual path:
from src.module_2 import clean  # or whatever it is
```

## ğŸ“ˆ Expected Coverage Increase

With these tests, you should reach:
- **src/load_data.py**: 0% â†’ ~90%+
- **src/query_data.py**: 48% â†’ ~85%+
- **src/module_2.1/clean.py**: 0% â†’ ~80%+
- **src/module_2.1/scrape.py**: 0% â†’ ~75%+
- **src/run.py**: 0% â†’ 100%

**Estimated total coverage: 80-90%+**

## ğŸ¯ Reaching 100% Coverage

To get from ~85% to 100%, you'll need to:

### 1. Add More Edge Case Tests
Focus on the uncovered lines shown by pytest-cov:

```powershell
# Run with detailed coverage report
pytest --cov=src --cov-report=html

# Open the HTML report to see uncovered lines
start htmlcov\index.html
```

### 2. Test Error Paths
Add tests for exception handling:

```python
@pytest.mark.db
def test_load_json_invalid_json(tmp_path):
    """Test loading invalid JSON raises error"""
    test_file = tmp_path / "bad.json"
    test_file.write_text("not valid json{")
    
    with pytest.raises(json.JSONDecodeError):
        load_data.load_json(str(test_file))
```

### 3. Test All Query Functions
The query_data.py file has many functions (Q4-Q11). Add tests for each:

```python
@pytest.mark.db
def test_q7_jhu_cs_masters():
    """Test JHU CS Masters query"""
    mock_conn = Mock()
    # ... mock cursor and result
    result = query_data.q7_jhu_cs_masters(mock_conn)
    assert result is not None
```

## ğŸš€ Testing Strategy

### Philosophy
These tests use **mocking** instead of real databases/networks:
- âœ… Tests run fast (seconds, not minutes)
- âœ… No external dependencies needed
- âœ… Deterministic results
- âœ… Can run in CI/CD

### What Gets Mocked
- **Database connections** - Uses Mock() instead of PostgreSQL
- **Network requests** - Mocks urllib/requests
- **File operations** - Mocks open() and tempfile
- **Subprocess calls** - Mocks LLM subprocess

### What Gets Tested
- **Logic** - Does the function work correctly?
- **Edge cases** - None values, empty lists, errors
- **Data flow** - Does data transform correctly?
- **Error handling** - Do exceptions get caught?

## ğŸ“ Update pytest.ini

Once you reach higher coverage, update pytest.ini:

```ini
[pytest]
# Gradually increase as you add tests
addopts = -v --cov=src --cov-report=term-missing --cov-fail-under=85

# Later when you hit 100%:
# addopts = -v --cov=src --cov-report=term-missing --cov-fail-under=100
```

## ğŸ“ Assignment Requirements Check

âœ… **Test Files**
- test_flask_page.py âœ“
- test_buttons.py âœ“
- test_analysis_format.py âœ“
- test_db_insert.py âœ“
- test_integration_end_to_end.py âœ“
- test_load_data.py âœ“ (NEW)
- test_query_data.py âœ“ (NEW)
- test_clean.py âœ“ (NEW)
- test_scrape.py âœ“ (NEW)
- test_run.py âœ“ (NEW)

âœ… **Test Markers**
- @pytest.mark.web âœ“
- @pytest.mark.buttons âœ“
- @pytest.mark.analysis âœ“
- @pytest.mark.db âœ“
- @pytest.mark.integration âœ“

âœ… **Coverage**
- Started: 27%
- With new tests: 80-90%+
- Target: 100%

## ğŸ› Troubleshooting

### Issue: ImportError on run.py
**Fix:** run.py uses `from app.__init__ import start_my_app` but your app uses `create_app`. Update run.py:

```python
from app import create_app

app = create_app()

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8080, debug=True)
```

### Issue: Test takes too long
**Fix:** Make sure mocking is working. If a test actually hits network/database, add more mocking.

### Issue: ModuleNotFoundError: psycopg2
**Fix:** Tests should mock psycopg connections. If you see this, the mock isn't working:

```python
@patch('src.load_data.psycopg.connect')  # Mock at the right path
def test_something(mock_connect):
    # ...
```

## ğŸ“š Next Steps

1. **Copy test files** to module_4/tests/
2. **Run pytest** - Fix any import errors
3. **Check coverage** - See what's uncovered
4. **Add edge case tests** - Get to 100%
5. **Commit & push** - Save your work!

```powershell
cd module_4
pytest -v --cov=src --cov-report=html
# Fix any issues
git add .
git commit -m "Module 4: Added comprehensive tests, 80%+ coverage"
git push
```

Good luck! ğŸš€
