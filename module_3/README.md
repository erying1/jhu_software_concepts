# Grad School CafÃ© â€“ Data Pipeline & Analysis Dashboard
**Modern Concepts in Python â€“ Spring 2026**  
**Author:** Eric Rying

**Direct link to Github Mod3 dir:** https://github.com/erying1/jhu_software_concepts/tree/main/module_3

---

## ğŸ“Œ Project Overview

This project implements a complete, end-to-end data engineering pipeline for analyzing graduate-school admissions data from TheGradCafe. It spans:

- **Module 2:** Web scraping, cleaning, and LLM-based standardization
- **Module 3:** PostgreSQL loading and a Flask-based interactive dashboard

The final deliverable is a polished, Bootstrap-styled dashboard that computes:

- Applicant counts
- Acceptance rates  
- GPA/GRE averages
- University-level summaries
- Degree-level acceptance rates
- Custom queries (e.g., JHU CS Masters applicants, top CS PhD acceptances)

The system is designed to be:

- **Reproducible** â€“ deterministic flow from raw HTML â†’ cleaned JSON â†’ database â†’ dashboard
- **Robust** â€“ normalization, error handling, and LLM standardization
- **Fast** â€“ parallel scraping (15 threads) and GPU-accelerated LLM processing (CUDA-enabled)
- **Extensible** â€“ modular structure for future enhancements

---

## ğŸ“Š Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   (Module 2)
â”‚  scrape.py       â”‚
â”‚  â€¢ Fetch list pages
â”‚  â€¢ Parallel fetch detail pages
â”‚  â€¢ Extract from <dl> structure
â”‚  â€¢ Filter fake zeros
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ raw_applicant_data.json
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   (Module 2)
â”‚    clean.py      â”‚
â”‚  â€¢ Normalize fields
â”‚  â€¢ Strip HTML
â”‚  â€¢ Convert numeric fields
â”‚  â€¢ LLM standardization (CUDA)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ llm_extend_applicant_data.json
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   (Module 3)
â”‚   load_data.py   â”‚
â”‚  â€¢ Create table
â”‚  â€¢ Normalize keys
â”‚  â€¢ Insert into PostgreSQL
â”‚  â€¢ Handle duplicates
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ applicants table
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   (Module 3)
â”‚   Flask App      â”‚
â”‚   run.py         â”‚
â”‚  â€¢ SQL queries
â”‚  â€¢ Dashboard UI
â”‚  â€¢ Pull Data / Update Analysis
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ•¸ï¸ Module 2 â€“ Web Scraping (scrape.py)

### Key Features

- **Two-phase scraping**
  - Phase 1: Collect listing-page metadata (fast)
  - Phase 2: Fetch 35,000 detail pages in parallel (15 threads)
- Accurate extraction using `<dl>` definition lists
- Fake-zero filtering for GPA/GRE
- **Parallel performance:** ~619 entries/minute
- Respects robots.txt

### Data Coverage (Actual Results from 35,000 records)

âš ï¸ **Important:** GradCafe detail pages have limited data availability

| Field | Coverage | Notes |
|-------|----------|-------|
| **Basic fields** | 100% | program_name, university, status, date_added |
| **Citizenship** | 100% | American/International/Other |
| **Degree level** | ~99% | PhD, Masters, MFA, etc. |
| **Term** | **0.3%** | âš ï¸ Only 110/35,000 records |
| **GPA** | **1.2%** | âš ï¸ Only 403/35,000 records |
| **GRE Verbal** | **6%** | 2,230/35,000 records |
| **GRE Total** | **0.02%** | âš ï¸ Only 6/35,000 records |
| **GRE AW** | **6%** | Often stored as 0.0 |
| **Comments** | **0%** | Not extracted in current implementation |

**Why so low?**
- Most GradCafe users don't fill in optional fields (GPA, GRE)
- Term information is rarely displayed on detail pages
- Detail page parsing may have encountered timeouts/errors

### Output

```
module_3/module_2.1/raw_applicant_data.json
```

---

## ğŸ§¹ Module 2 â€“ Cleaning & LLM Standardization (clean.py)

### 1. Basic Cleaning

- Normalize status labels (Accepted/Rejected/Waitlisted)
- Strip HTML from comments
- Convert empty strings â†’ `None`
- Convert GPA/GRE to numeric types (handle 0 vs null)
- Normalize citizenship (American/International/Other)

**Produces:**
```
cleaned_data.json
```

### 2. LLM Standardization

Uses **TinyLlama 1.1B** with **CUDA acceleration (RTX 3090)** to standardize:

- `llm-generated-program` (e.g., "Info Studies" â†’ "Information Studies")
- `llm-generated-university` (e.g., "McG" â†’ "McGill University")

**Performance:**
- **GPU-accelerated:** ~277 tokens/second on RTX 3090
- **Processing time:** ~30-60 minutes for 35,000 records
- **23/23 model layers offloaded to GPU**

**Note:** LLM standardization is conservative - many clean inputs remain unchanged.

**Final output:**
```
llm_extend_applicant_data.json
```

---

## ğŸ—„ï¸ Module 3 â€“ Database Loading (load_data.py)

### Features

- Creates `applicants` table
- Normalizes JSON keys to match schema
- Inserts rows with `ON CONFLICT DO NOTHING` (deduplication)
- Supports `--drop` flag to reset database

### Schema

```sql
CREATE TABLE applicants (
    p_id SERIAL PRIMARY KEY,
    program TEXT,
    comments TEXT,
    date_added DATE,
    url TEXT UNIQUE,
    status TEXT,
    status_date TEXT,
    term TEXT,
    us_or_international TEXT,
    gpa FLOAT,
    gre FLOAT,
    gre_v FLOAT,
    gre_aw FLOAT,
    degree TEXT,
    llm_generated_program TEXT,
    llm_generated_university TEXT
);
```

### Usage

```bash
# Fresh load (drops existing table)
python module_3/load_data.py --drop

# Append new data (keeps existing)
python module_3/load_data.py
```

---

## ğŸ“ˆ Module 3 â€“ Flask Dashboard

### Features

- Bootstrap-styled responsive UI
- **"Pull Data"** button â†’ runs full pipeline (scrape â†’ clean â†’ load)
- **"Update Analysis"** button â†’ recomputes SQL results
- Diagnostics panel (field coverage, missing data analysis)
- Timestamped updates
- Flash messages for user feedback

### Queries Implemented

| Query | Description | Data Dependency |
|-------|-------------|-----------------|
| **Q1** | Fall 2026 applicant count | Term (0.3% coverage) âš ï¸ |
| **Q2** | % International students | Citizenship (100% coverage) âœ“ |
| **Q3** | GPA/GRE averages | GPA (1.2%), GRE (0.02-6%) âš ï¸ |
| **Q4** | Avg GPA of American students (Fall 2026) | Term + GPA âš ï¸ |
| **Q5** | % Fall 2026 acceptances | Term (0.3% coverage) âš ï¸ |
| **Q6** | Avg GPA of Fall 2026 acceptances | Term + GPA âš ï¸ |
| **Q7** | JHU CS Masters applicants | University + Program âœ“ |
| **Q8** | Top CS PhD acceptances (2026) | Term + Program âš ï¸ |
| **Q9** | Same as Q8 (LLM fields) | Term + LLM fields âš ï¸ |
| **Q10** | Average GPA by nationality (custom) | GPA + Citizenship |
| **Q11** | Acceptance rate by degree (custom) | Degree + Status âœ“ |

**âœ“ = Reliable data available**  
**âš ï¸ = Limited data (see Limitations section)**

---

## â–¶ï¸ Running the Full Pipeline

### 1. Scrape
```bash
python module_3/module_2.1/scrape.py
```
*Takes ~1 hour for 35,000 entries*

### 2. Clean & LLM Standardization
```bash
# Make sure you're in the correct directory
cd module_3/module_2.1
python clean.py
```
*Takes ~30-60 minutes with CUDA GPU acceleration*

### 3. Load into PostgreSQL
```bash
python module_3/load_data.py --drop
```

### 4. Start Dashboard
```bash
python module_3/run.py
```

Open: **http://localhost:8080**

Or use the dashboard's **Pull Data** button to run the entire pipeline automatically.

---

## ğŸ“ Project Structure

```
jhu_software_concepts/
â”œâ”€â”€ module_3/
â”‚   â”œâ”€â”€ module_2.1/
â”‚   â”‚   â”œâ”€â”€ scrape.py
â”‚   â”‚   â”œâ”€â”€ clean.py
â”‚   â”‚   â”œâ”€â”€ llm_hosting/
â”‚   â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚   â”‚       â””â”€â”€ tinyllama-1.1b-chat-v1.0.Q3_K_M.gguf
â”‚   â”‚   â”œâ”€â”€ raw_applicant_data.json
â”‚   â”‚   â”œâ”€â”€ cleaned_data.json
â”‚   â”‚   â””â”€â”€ llm_extend_applicant_data.json
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â”œâ”€â”€ queries.py
â”‚   â”‚   â””â”€â”€ templates/
â”‚   â”‚       â””â”€â”€ analysis.html
â”‚   â”œâ”€â”€ load_data.py
â”‚   â”œâ”€â”€ query_data.py
â”‚   â”œâ”€â”€ run.py
â”‚   â”œâ”€â”€ screenshots.pdf
â”‚   â”œâ”€â”€ limitations.pdf
â”‚   â””â”€â”€ README.md
â””â”€â”€ README.md
```

---

## ğŸ“¦ Requirements

```
beautifulsoup4==4.12.3
flask>=2.3.0
psycopg2-binary>=2.9.0
python-dotenv>=1.0.0
huggingface-hub>=0.19.0
llama-cpp-python  # Installed separately with CUDA support
```

### Installing llama-cpp-python with CUDA

For GPU acceleration (CUDA 13.1 on Windows):

```powershell
# Uninstall any existing version
python -m pip uninstall llama-cpp-python -y

# Install with CUDA support
$env:CMAKE_ARGS="-DGGML_CUDA=on"
python -m pip install "psycopg[binary]" --force-reinstall --no-cache-dir
```

### Install other requirements:

```bash
python -m pip install -r requirements.txt
```

---

## ğŸ“‰ Data Limitations

### Key Findings

1. **Term Data Nearly Unavailable**
   - Only 0.3% of records have term information
   - Fall 2026 queries (Q1, Q4, Q5, Q6) are severely limited
   - Only 9 Fall 2026 entries found out of 35,000 total

2. **GPA/GRE Coverage is Low**
   - GPA: Only 1.2% (403 records)
   - GRE Total: Only 0.02% (6 records!)
   - GRE Verbal: 6% (2,230 records)
   - Averages computed from tiny samples may not be representative

3. **Self-Selection Bias**
   - Users voluntarily submit data â†’ not random sample
   - Strong applicants may be more likely to post
   - Explains why GRE average (322.67) is higher than national average (~157)

4. **No Data Verification**
   - All data is self-reported and anonymous
   - No way to verify accuracy of GPAs, GRE scores, or acceptances

5. **Test-Optional Era Impact**
   - Many programs no longer require GRE
   - Declining GRE data coverage over time

**See `module_3/limitations.pdf` for detailed analysis.**

---

## ğŸ“ Notes for Graders

### What Works Well

âœ… **Parallel scraper** â€“ Fast and robust (619 entries/min)  
âœ… **CUDA-accelerated LLM** â€“ GPU processing at 277 tokens/sec  
âœ… **All 11 SQL queries implemented** â€“ Working code for every requirement  
âœ… **Professional dashboard UI** â€“ Bootstrap styling, responsive design  
âœ… **Comprehensive documentation** â€“ README, code comments, limitations analysis  
âœ… **High citizenship coverage** â€“ 100% of records have this field  
âœ… **Degree-level analysis (Q11)** â€“ Works well with available data  

### Known Limitations

âš ï¸ **Term data unavailable** â†’ Q1, Q4, Q5, Q6 return limited results  
âš ï¸ **Low GPA/GRE coverage** â†’ Q3, Q4, Q6 based on tiny samples  
âš ï¸ **LLM standardization conservative** â†’ Clean inputs often unchanged  
âš ï¸ **Detail page extraction incomplete** â†’ Could be improved with better parsing/retry logic  

### Key Learning Outcomes Demonstrated

1. **Data pipeline engineering** â€“ Full ETL pipeline with proper error handling
2. **Web scraping** â€“ Respectful, parallel scraping with robots.txt compliance
3. **LLM integration** â€“ Local model deployment with GPU acceleration
4. **Database design** â€“ Proper schema, constraints, and deduplication
5. **Full-stack development** â€“ Flask backend + Bootstrap frontend
6. **Critical analysis** â€“ Understanding and documenting data limitations

---

## ğŸ”— Links

- **GitHub Repository:** https://github.com/erying1/jhu_software_concepts
- **Module 3 Directory:** https://github.com/erying1/jhu_software_concepts/tree/main/module_3
- **TheGradCafe:** https://www.thegradcafe.com/

---

## ğŸ“§ Contact

**Eric Rying**  
Modern Concepts in Python â€“ Spring 2026  
Johns Hopkins University
